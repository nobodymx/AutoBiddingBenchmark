config = {
    "TransitionModel": {
        "input_dim": 41,
        "output_dim": 82,
        "ensemble_size": 4,
        "reward_penalty_coeff": 5,
        "decay_weights": [0.000025, 0.00005, 0.000075, 0.0001, 0.0001],
        "mlp_hidden_layer": [10, 10, 5],
        "trans_mlp_hidden_layers": [10, 10, 5],
        "total_mlp_hidden_layers": [10, 10, 5],
        "env_model_batch_size": 500,

    },
    "SAC": {
        "obs_dim": 4,
        "actor_bb_out_dim": 50,
        "actor_hidden_dim": [10, 50],
        "action_dim": 1,
        "critic_bb_out_dim": 50,
        "critic_hidden_dim": [10, 50],
        "auto_alpha": False,
        "alpha": 0.2,
        "target_entropy": False,
        "act_fn": "relu",
        "out_act_fn": "identity",
        "actor_lr": 2e-5,
        "critic_lr": 2e-4,
        "alpha_lr": 3e-4,
        "gamma": 1,
        "lr_decay": 1.0,
        "tau": 0.005,
        "policy_train_epoch": 10000,
    },
    "basic_config": {
        "num_controllable_agent": 1,
        "num_uncontrollable_agents": 29,
        "num_agents": 30,
        "budget_level": [50, 100, 200, 500, 1000, 2000],
        "budgets": [50, 100, 200, 500, 1000, 2000, 50, 100, 200, 500, 1000, 2000, 50, 100, 200, 500, 1000, 2000, 50,
                    100, 200, 500, 1000, 2000, 50, 100, 200, 500, 1000,],
        "agent_cate": 6,
        "num_tick": 24,
        "reserve_pv_price": 0.0001,
        "min_remaining_budget": 0.1,
        "is_sparse": False,
        "device": "cpu",
        "pv_num": 7700000,
    },
}
